{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, exceptions\n",
    "from tqdm.auto import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>focus_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>What is (are) Rectal Cancer ?</td>\n",
       "      <td>Key Points\\n                    - Rectal cance...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>Rectal Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Who is at risk for Pancreatic Neuroendocrine T...</td>\n",
       "      <td>Having certain syndromes can increase the risk...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>Pancreatic Neuroendocrine Tumors (Islet Cell T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>How to diagnose Oropharyngeal Cancer ?</td>\n",
       "      <td>Tests that examine the mouth and throat are us...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>Oropharyngeal Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What is (are) Adult Central Nervous System Tum...</td>\n",
       "      <td>Key Points\\n                    - An adult cen...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>Adult Central Nervous System Tumors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>How to diagnose Endometrial Cancer ?</td>\n",
       "      <td>Tests that examine the endometrium are used to...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>Endometrial Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "226                      What is (are) Rectal Cancer ?   \n",
       "191  Who is at risk for Pancreatic Neuroendocrine T...   \n",
       "183             How to diagnose Oropharyngeal Cancer ?   \n",
       "10   What is (are) Adult Central Nervous System Tum...   \n",
       "96                How to diagnose Endometrial Cancer ?   \n",
       "\n",
       "                                                answer     source  \\\n",
       "226  Key Points\\n                    - Rectal cance...  CancerGov   \n",
       "191  Having certain syndromes can increase the risk...  CancerGov   \n",
       "183  Tests that examine the mouth and throat are us...  CancerGov   \n",
       "10   Key Points\\n                    - An adult cen...  CancerGov   \n",
       "96   Tests that examine the endometrium are used to...  CancerGov   \n",
       "\n",
       "                                            focus_area  \n",
       "226                                      Rectal Cancer  \n",
       "191  Pancreatic Neuroendocrine Tumors (Islet Cell T...  \n",
       "183                               Oropharyngeal Cancer  \n",
       "10                 Adult Central Nervous System Tumors  \n",
       "96                                  Endometrial Cancer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df = pd.read_csv('data\\cleaned_data.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 292 entries, 0 to 291\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   question    292 non-null    object\n",
      " 1   answer      292 non-null    object\n",
      " 2   source      292 non-null    object\n",
      " 3   focus_area  292 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>source</th>\n",
       "      <th>focus_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>292</td>\n",
       "      <td>291</td>\n",
       "      <td>9</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>What is (are) 21-hydroxylase deficiency ?</td>\n",
       "      <td>New types of treatment are being tested in cli...</td>\n",
       "      <td>CancerGov</td>\n",
       "      <td>21-hydroxylase deficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question  \\\n",
       "count                                         292   \n",
       "unique                                        292   \n",
       "top     What is (are) 21-hydroxylase deficiency ?   \n",
       "freq                                            1   \n",
       "\n",
       "                                                   answer     source  \\\n",
       "count                                                 292        292   \n",
       "unique                                                291          9   \n",
       "top     New types of treatment are being tested in cli...  CancerGov   \n",
       "freq                                                    2         72   \n",
       "\n",
       "                       focus_area  \n",
       "count                         292  \n",
       "unique                        292  \n",
       "top     21-hydroxylase deficiency  \n",
       "freq                            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "CancerGov            72\n",
       "NIDDK                66\n",
       "GARD                 51\n",
       "NHLBI                47\n",
       "GHR                  26\n",
       "NIHSeniorHealth      23\n",
       "MPlusHealthTopics     5\n",
       "CDC                   1\n",
       "NINDS                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sources = df['source'].value_counts()\n",
    "common_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_length</th>\n",
       "      <th>answer_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.119863</td>\n",
       "      <td>2193.965753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.951042</td>\n",
       "      <td>2669.869616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>581.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>1128.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.250000</td>\n",
       "      <td>2859.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>17810.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_length  answer_length\n",
       "count       292.000000     292.000000\n",
       "mean         46.119863    2193.965753\n",
       "std          15.951042    2669.869616\n",
       "min          22.000000      31.000000\n",
       "25%          35.000000     581.500000\n",
       "50%          43.000000    1128.000000\n",
       "75%          52.250000    2859.000000\n",
       "max         154.000000   17810.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_len= df['question'].apply(len)\n",
    "answer_len= df['answer'].apply(len)\n",
    "\n",
    "lengths_df = pd.DataFrame({'question_length': question_len,'answer_length': answer_len})\n",
    "lengths_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Search for Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elasticsearch instance\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Define index name and settings\n",
    "index_name = \"health-questions\"\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"answer\": {\"type\": \"text\"},\n",
    "            \"source\": {\"type\": \"text\"},\n",
    "            \"focus_area\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "source": [
    "# Create the index if it doesn't exist\n",
    "\n",
    "try:\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body=index_settings)\n",
    "        print(\"Index created successfully\")\n",
    "    else:\n",
    "        print(\"Index already exists\")\n",
    "except exceptions.ConnectionError as e:\n",
    "    print(f\"Failed to create index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042bc238fec7464b855c564c97708c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert DataFrame to dictionary format for Elasticsearch\n",
    "documents = df.to_dict(orient='records')\n",
    "\n",
    "# Index the documents\n",
    "for doc in tqdm(documents):\n",
    "    es.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('data/data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that retrieves documents and matches user queries\n",
    "\n",
    "def search(query, max_results=5):\n",
    "    search_query = {\n",
    "        \"size\": max_results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"answer\", 'focus_area'],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=search_query)\n",
    "    documents = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that creates a prompt for an LLM to answer health-related questions based on the given data\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a healthcare assistant AI. Answer the QUESTION based on the CONTEXT provided from a health FAQ database.\n",
    "Use only the facts from the CONTEXT to provide an accurate, clear, and concise answer.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context += f\"Question: {doc['question']}\\nAnswer: {doc['answer']}\\nSource: {doc['source']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an OpenAI client\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample query\n",
    "\n",
    "query = 'how do i prevent diabetes?'\n",
    "rag(query)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs-Course-DataTalksClub-n7mUlEcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
